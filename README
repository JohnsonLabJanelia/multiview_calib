# Multiple view calibration tool

## Prerequisites

- numpy
- scipy
- imageio
- matplotlib
- OpenCV

## Installation
```
export PYTHONPATH="...parent folder...:$PYTHONPATH"
```

## Usage

#### Compute intrinsic parameters:
Take a video or pictures of the checkerboard from multiple positions. Make sure the checkerboard goes right on the edges of the image plane!
https://markhedleyjones.com/storage/checkerboards/Checkerboard-A4-30mm-8x6.pdf
Once printed on paper, make sure the squares measure 30mmx30mm, if not, remove any autoresizing printer's config.

Extract the frames:
```
ffmpeg -i VIDEO -r 0.5 frames/frame_%04d.jpg
```
Run the following script:
```
python compute_intrinsics.py --folder_images ./frames -ich 6 -icw 8 -s 30 -t 24 --debug
```
To understand if the calibration is correct you have to perform a visual inspction of the undistorted images that have been saved. The lines in the images should be straight and the picture has to look like a normal picture. In case of failure update Opencv or re-take the video/pictures.

#### Compute relative poses:
At this step we compute the relative poses between pairs of views. These rigid transformations will then be chained one another to compute the pose of each camera w.r.t the first camera. In order to do so, we have to manually define a minimal set of pairs of views that connect every camera. This is done in the file `setup.json`. 
The file named `landmarks.json` contains precise image points for each view that are used to compute fundamental matrices and poses. The file `Ã¬ntrinsics.json` contains the intrinsic parameters for each view. The file `filenames.json` contains one filename of an image for each view; it is used for visualisation purposes.
Check section `Input files` for more details on the file formats.

```
python compute_relative_poses.py -s setup.json -i intrinsics.json -l landmarks.json -f filenames.json --dump_images 
```
The result of this operation are relative poses from the first to second camera for each pairs of views. The poses are up to scale, in other words the translation is a unit vector.

The following command is an alternative. It computes the final relative pose from view1 to view2 as an average of relative poses computed using N other and different views.
```
python compute_relative_poses_robust.py -s setup.json -i intrinsics.json -l landmarks.json -m lmeds -n 5 -f filenames.json --dump_images
```

#### Concatenate relative poses:
In this step we concatenate/chain all the relative poses to obtain an estimate of the actual camera poses. The poses are defined w.r.t the first camera. At every concatenation we scale the current relative pose to match the scale of the previous ones. This to have roughly the same scale for each camera.
The file `relative_poses.json` is the output of the previous step.
```
python concatenate_relative_poses.py -s setup.json -r relative_poses.json --dump_images 
```
#### Bundle adjustment:
Least squares refinement of intrinsic and extrinsic parameters and 3D points. The camera rig is still up to a scale at this point.
The file `poses.json` is the output of the previous step.
```
python bundle_adjustment.py -s setup.json -i intrinsics.json -e poses.json -l landmarks.json -f filenames.json --dump_images -c ba_config.json 
```
#### Transformation to global reference system:
Give correspondences between the 3D results of the bundle adjustment and 3D points of the world coordinate system, we compute rotation translation and scale that match the two point sets.
```
python global_registration.py -e ba_poses.json -p ba_points.json world_points.json --dump_images  
```
The result of this step are the camera poses defined in this new coordinate system.

## Input files
The file `setup.json` contains the name of the views and the minimal number of pairs of views that allows to connect all the cameras togheter:
```json
{
 "views": [ "cam0", "cam1", "cam2", "cam3"], 
 "minimal_tree": [["cam0","cam1"], ["cam1","cam2"], ["cam3","cam0"]]
}
```
The file `landmarks.json` contains the points used to compute the poses. Each landmark has an associated timestamp. This defines a time when the landmark is visible. If the same landmark is visible in other views the same timestamp should be used. Multiple landmarks can have the same timestamp. 
```json
{
 "cam0":{landmarks": [[530.1256, 877.56], [2145.5564, 987.4574], ..., [1023, 126]], 
         "timestamp": [0, 0, ..., 3040]},
 ...
 "cam3":{landmarks": [[430.1256, 377.56], [2245.5564, 387.4574], ..., [2223, 1726]], 
         "timestamp": [0, 0, ..., 3040]}         
}
```
The file `intrinsics.json` contains the instrinsics parameters in the following format:
```json
{
 "cam0": { "K": [[1798.760123221333, 0.0, 1947.1889719803005], 
                  [0.0, 1790.0624403935456, 1091.2910152343356],
                  [ 0.0, 0.0, 1.0]],
            "dist": [-0.22790810,0.0574260,0.00032600,-0.00047905,-0.0068488]},
 ...           
 "cam3": { "K": [[1778.560123221333, 0.0, 1887.1889719803005], 
                  [0.0, 1780.0624403935456, 1081.2910152343356],
                  [ 0.0, 0.0, 1.0]],
            "dist": [-0.2390810,0.0554260,0.00031600,-0.00041905,-0.0062488]}
}
```
The file `filenames.json` contains one filename for each view. It is used for visualisation purposes only:
```json
{
 "cam0": "somewhere/filename_cam0.jpg",
 ...           
 "cam3": "somewhere/filename_cam3.jpg",
}
```
The file `ba_config.json` contains the configuration for the bundle adjustment. A typical configuration is the following:
```json
{
  "each_training": 1
  "each_visualisation": 1,
  "th_outliers_early": 1000.0,
  "th_outliers": 50,
  "optimize_points": true,
  "optimize_camera_params": true,
  "bounds": true,  
  "bounds_cp": [ 
    0.3, 0.3, 0.3,
    2, 2, 2,
    10, 10, 10, 10,
    0.01, 0.01, 0, 0, 0
  ],
  "bounds_pt": [
    1000,
    1000,
    1000
  ],
  "max_nfev": 200,
  "max_nfev2": 200,
  "ftol": 1e-08,
  "xtol": 1e-08,  
  "loss": "linear",
  "f_scale": 1,
  "output_path": "output/bundle_adjustment/",
}
```
## License

